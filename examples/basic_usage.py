#!/usr/bin/env python3
"""
WebMainBench åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
"""

import json
from pathlib import Path

# å¯¼å…¥ WebMainBench æ¨¡å—
from webmainbench import (
    DataLoader, DataSaver, BenchmarkDataset, DataSample,
    ExtractorFactory, Evaluator, 
    format_results, setup_logging
)


def create_sample_dataset():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®é›†"""
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ® - åŒ…å«å¤šç§å†…å®¹ç±»å‹ï¼ˆä»£ç ã€å…¬å¼ã€è¡¨æ ¼ç­‰ï¼‰
    samples = [
        {
            "track_id": "sample-001-programming-tutorial",
            "html": '''<html><body>
                <h1 cc-select="true">Pythonç¼–ç¨‹æ•™ç¨‹</h1>
                <p cc-select="true">è¿™æ˜¯ä¸€ä¸ªPythonåŸºç¡€æ•™ç¨‹ï¼Œå±•ç¤ºå¦‚ä½•å®šä¹‰å‡½æ•°ã€‚</p>
                <pre cc-select="true"><code>def greet(name):
    """é—®å€™å‡½æ•°"""
    return f"Hello, {name}!"

# ä½¿ç”¨ç¤ºä¾‹
result = greet("World")
print(result)</code></pre>
                <p cc-select="true">è¿™ä¸ªå‡½æ•°å¯ä»¥ç”¨æ¥é—®å€™ä»»ä½•äººã€‚</p>
            </body></html>''',
            "groundtruth_content": '''# Pythonç¼–ç¨‹æ•™ç¨‹

è¿™æ˜¯ä¸€ä¸ªPythonåŸºç¡€æ•™ç¨‹ï¼Œå±•ç¤ºå¦‚ä½•å®šä¹‰å‡½æ•°ã€‚

```python
def greet(name):
    """é—®å€™å‡½æ•°"""
    return f"Hello, {name}!"

# ä½¿ç”¨ç¤ºä¾‹
result = greet("World")
print(result)
```

è¿™ä¸ªå‡½æ•°å¯ä»¥ç”¨æ¥é—®å€™ä»»ä½•äººã€‚''',
            "groundtruth_content_list": [
                {"type": "heading", "content": "Pythonç¼–ç¨‹æ•™ç¨‹", "level": 1},
                {"type": "paragraph", "content": "è¿™æ˜¯ä¸€ä¸ªPythonåŸºç¡€æ•™ç¨‹ï¼Œå±•ç¤ºå¦‚ä½•å®šä¹‰å‡½æ•°ã€‚"},
                {"type": "code", "content": 'def greet(name):\n    """é—®å€™å‡½æ•°"""\n    return f"Hello, {name}!"\n\n# ä½¿ç”¨ç¤ºä¾‹\nresult = greet("World")\nprint(result)'},
                {"type": "paragraph", "content": "è¿™ä¸ªå‡½æ•°å¯ä»¥ç”¨æ¥é—®å€™ä»»ä½•äººã€‚"}
            ],
            "url": "https://python-tutorial.example.com/functions",
            "layout_id": "python-tutorial_1",
            "max_layer_n": 8,
            "url_host_name": "python-tutorial.example.com",
            "raw_warc_path": "s3://cc-raw-tutorials/crawl-data/CC-MAIN-2025-13/segments/1742004433093.21/warc/tutorial-001.warc.gz",
            "language": "en",
            "__dom_depth": 12,
            "__dom_width": 5240,
            "__type": "__programming_tutorial",
            "__tag": "CODE_CONTENT",
            "marked_type": "normal",
            "content_type": "programming"
        },
        {
            "track_id": "sample-002-math-formulas",
            "html": '''<html><body>
                <h1 cc-select="true">æ•°å­¦å…¬å¼ç¤ºä¾‹</h1>
                <p cc-select="true">è¿™é‡Œå±•ç¤ºä¸€äº›åŸºæœ¬çš„æ•°å­¦å…¬å¼ã€‚</p>
                <p cc-select="true">å‹¾è‚¡å®šç†ï¼šaÂ² + bÂ² = cÂ²</p>
                <div cc-select="true" class="formula">
                    <p>äºŒæ¬¡æ–¹ç¨‹çš„è§£ä¸ºï¼š</p>
                    <p>x = (-b Â± âˆš(bÂ² - 4ac)) / 2a</p>
                </div>
                <p cc-select="true">æ¬§æ‹‰å…¬å¼æ˜¯æ•°å­¦ä¸­æœ€ç¾ä¸½çš„å…¬å¼ä¹‹ä¸€ï¼še^(iÏ€) + 1 = 0</p>
                <table cc-select="true">
                    <tr><th>å‡½æ•°</th><th>å¯¼æ•°</th></tr>
                    <tr><td>xÂ²</td><td>2x</td></tr>
                    <tr><td>sin(x)</td><td>cos(x)</td></tr>
                </table>
            </body></html>''',
            "groundtruth_content": '''# æ•°å­¦å…¬å¼ç¤ºä¾‹

è¿™é‡Œå±•ç¤ºä¸€äº›åŸºæœ¬çš„æ•°å­¦å…¬å¼ã€‚

å‹¾è‚¡å®šç†ï¼š$a^2 + b^2 = c^2$

äºŒæ¬¡æ–¹ç¨‹çš„è§£ä¸ºï¼š

$$x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$$

æ¬§æ‹‰å…¬å¼æ˜¯æ•°å­¦ä¸­æœ€ç¾ä¸½çš„å…¬å¼ä¹‹ä¸€ï¼š$e^{i\\pi} + 1 = 0$

| å‡½æ•° | å¯¼æ•° |
|------|------|
| xÂ² | 2x |
| sin(x) | cos(x) |''',
            "groundtruth_content_list": [
                {"type": "heading", "content": "æ•°å­¦å…¬å¼ç¤ºä¾‹", "level": 1},
                {"type": "paragraph", "content": "è¿™é‡Œå±•ç¤ºä¸€äº›åŸºæœ¬çš„æ•°å­¦å…¬å¼ã€‚"},
                {"type": "paragraph", "content": "å‹¾è‚¡å®šç†ï¼šaÂ² + bÂ² = cÂ²"},
                {"type": "paragraph", "content": "äºŒæ¬¡æ–¹ç¨‹çš„è§£ä¸ºï¼š"},
                {"type": "equation-interline", "content": "x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}"},
                {"type": "paragraph", "content": "æ¬§æ‹‰å…¬å¼æ˜¯æ•°å­¦ä¸­æœ€ç¾ä¸½çš„å…¬å¼ä¹‹ä¸€ï¼še^(iÏ€) + 1 = 0"},
                {"type": "table", "content": "| å‡½æ•° | å¯¼æ•° |\n|------|------|\n| xÂ² | 2x |\n| sin(x) | cos(x) |"}
            ],
            "url": "https://math-examples.edu/formulas",
            "layout_id": "math-examples_2",
            "max_layer_n": 10,
            "url_host_name": "math-examples.edu",
            "raw_warc_path": "s3://cc-raw-academic/crawl-data/CC-MAIN-2025-13/segments/1742004433093.21/warc/math-002.warc.gz",
            "language": "zh",
            "__dom_depth": 15,
            "__dom_width": 6850,
            "__type": "__academic_content",
            "__tag": "FORMULA_TABLE",
            "marked_type": "normal",
            "content_type": "academic"
        },
        {
            "track_id": "sample-003-data-analysis",
            "html": '''<html><body>
                <h1 cc-select="true">æ•°æ®åˆ†ææŠ¥å‘Š</h1>
                <p cc-select="true">ä»¥ä¸‹æ˜¯2024å¹´ç¬¬ä¸€å­£åº¦çš„é”€å”®æ•°æ®åˆ†æã€‚</p>
                <h2 cc-select="true">æ•°æ®å¤„ç†ä»£ç </h2>
                <pre cc-select="true"><code>import pandas as pd
import numpy as np

# è¯»å–æ•°æ®
df = pd.read_csv('sales_q1_2024.csv')

# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
monthly_avg = df.groupby('month')['sales'].mean()
print(f"å¹³å‡é”€å”®é¢: {monthly_avg}")</code></pre>
                <h2 cc-select="true">é”€å”®ç»Ÿè®¡</h2>
                <table cc-select="true">
                    <tr><th>æœˆä»½</th><th>é”€å”®é¢(ä¸‡å…ƒ)</th><th>å¢é•¿ç‡</th></tr>
                    <tr><td>1æœˆ</td><td>120.5</td><td>+15.2%</td></tr>
                    <tr><td>2æœˆ</td><td>135.8</td><td>+12.7%</td></tr>
                    <tr><td>3æœˆ</td><td>148.3</td><td>+9.2%</td></tr>
                </table>
                <p cc-select="true">æ ‡å‡†å·®å…¬å¼ï¼šÏƒ = âˆš(Î£(xi - Î¼)Â² / n)</p>
                <p cc-select="true">æ€»ä½“æ¥çœ‹ï¼Œç¬¬ä¸€å­£åº¦é”€å”®è¡¨ç°è‰¯å¥½ï¼Œå‘ˆç°ç¨³å®šå¢é•¿è¶‹åŠ¿ã€‚</p>
            </body></html>''',
            "groundtruth_content": '''# æ•°æ®åˆ†ææŠ¥å‘Š

ä»¥ä¸‹æ˜¯2024å¹´ç¬¬ä¸€å­£åº¦çš„é”€å”®æ•°æ®åˆ†æã€‚

## æ•°æ®å¤„ç†ä»£ç 

```python
import pandas as pd
import numpy as np

# è¯»å–æ•°æ®
df = pd.read_csv('sales_q1_2024.csv')

# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
monthly_avg = df.groupby('month')['sales'].mean()
print(f"å¹³å‡é”€å”®é¢: {monthly_avg}")
```

## é”€å”®ç»Ÿè®¡

| æœˆä»½ | é”€å”®é¢(ä¸‡å…ƒ) | å¢é•¿ç‡ |
|------|-------------|--------|
| 1æœˆ | 120.5 | +15.2% |
| 2æœˆ | 135.8 | +12.7% |
| 3æœˆ | 148.3 | +9.2% |

æ ‡å‡†å·®å…¬å¼ï¼š$\\sigma = \\sqrt{\\frac{\\Sigma(x_i - \\mu)^2}{n}}$

æ€»ä½“æ¥çœ‹ï¼Œç¬¬ä¸€å­£åº¦é”€å”®è¡¨ç°è‰¯å¥½ï¼Œå‘ˆç°ç¨³å®šå¢é•¿è¶‹åŠ¿ã€‚''',
            "groundtruth_content_list": [
                {"type": "heading", "content": "æ•°æ®åˆ†ææŠ¥å‘Š", "level": 1},
                {"type": "paragraph", "content": "ä»¥ä¸‹æ˜¯2024å¹´ç¬¬ä¸€å­£åº¦çš„é”€å”®æ•°æ®åˆ†æã€‚"},
                {"type": "heading", "content": "æ•°æ®å¤„ç†ä»£ç ", "level": 2},
                {"type": "code", "content": "import pandas as pd\nimport numpy as np\n\n# è¯»å–æ•°æ®\ndf = pd.read_csv('sales_q1_2024.csv')\n\n# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯\nmonthly_avg = df.groupby('month')['sales'].mean()\nprint(f\"å¹³å‡é”€å”®é¢: {monthly_avg}\")"},
                {"type": "heading", "content": "é”€å”®ç»Ÿè®¡", "level": 2},
                {"type": "table", "content": "| æœˆä»½ | é”€å”®é¢(ä¸‡å…ƒ) | å¢é•¿ç‡ |\n|------|-------------|--------|\n| 1æœˆ | 120.5 | +15.2% |\n| 2æœˆ | 135.8 | +12.7% |\n| 3æœˆ | 148.3 | +9.2% |"},
                {"type": "paragraph", "content": "æ ‡å‡†å·®å…¬å¼ï¼šÏƒ = âˆš(Î£(xi - Î¼)Â² / n)"},
                {"type": "paragraph", "content": "æ€»ä½“æ¥çœ‹ï¼Œç¬¬ä¸€å­£åº¦é”€å”®è¡¨ç°è‰¯å¥½ï¼Œå‘ˆç°ç¨³å®šå¢é•¿è¶‹åŠ¿ã€‚"}
            ],
            "url": "https://data-report.company.com/q1-2024-analysis",
            "layout_id": "data-report_3",
            "max_layer_n": 12,
            "url_host_name": "data-report.company.com",
            "raw_warc_path": "s3://cc-raw-business/crawl-data/CC-MAIN-2025-13/segments/1742004433093.21/warc/analysis-003.warc.gz",
            "language": "zh",
            "__dom_depth": 18,
            "__dom_width": 8420,
            "__type": "__business_report",
            "__tag": "MIXED_CONTENT",
            "marked_type": "normal",
            "content_type": "business"
        },
        {
            "track_id": "sample-004-algorithm-explanation",
            "html": '''<html><body>
                <h1 cc-select="true">ç®—æ³•å¤æ‚åº¦åˆ†æ</h1>
                <p cc-select="true">è¿™é‡Œä»‹ç»å¸¸è§ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ã€‚</p>
                <h2 cc-select="true">å¿«é€Ÿæ’åºå®ç°</h2>
                <pre cc-select="true"><code>def quicksort(arr):
    if len(arr) <= 1:
        return arr
    
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    
    return quicksort(left) + middle + quicksort(right)</code></pre>
                <h2 cc-select="true">å¤æ‚åº¦å¯¹æ¯”</h2>
                <table cc-select="true">
                    <tr><th>ç®—æ³•</th><th>æœ€å¥½æƒ…å†µ</th><th>å¹³å‡æƒ…å†µ</th><th>æœ€åæƒ…å†µ</th></tr>
                    <tr><td>å¿«é€Ÿæ’åº</td><td>O(n log n)</td><td>O(n log n)</td><td>O(nÂ²)</td></tr>
                    <tr><td>å½’å¹¶æ’åº</td><td>O(n log n)</td><td>O(n log n)</td><td>O(n log n)</td></tr>
                    <tr><td>å†’æ³¡æ’åº</td><td>O(n)</td><td>O(nÂ²)</td><td>O(nÂ²)</td></tr>
                </table>
                <p cc-select="true">Masterå®šç†ï¼šT(n) = aT(n/b) + f(n)</p>
                <p cc-select="true">å…¶ä¸­ a â‰¥ 1, b > 1 æ˜¯å¸¸æ•°ï¼Œf(n) æ˜¯æ­£å‡½æ•°ã€‚</p>
            </body></html>''',
            "groundtruth_content": '''# ç®—æ³•å¤æ‚åº¦åˆ†æ

è¿™é‡Œä»‹ç»å¸¸è§ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ã€‚

## å¿«é€Ÿæ’åºå®ç°

```python
def quicksort(arr):
    if len(arr) <= 1:
        return arr
    
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    
    return quicksort(left) + middle + quicksort(right)
```

## å¤æ‚åº¦å¯¹æ¯”

| ç®—æ³• | æœ€å¥½æƒ…å†µ | å¹³å‡æƒ…å†µ | æœ€åæƒ…å†µ |
|------|----------|----------|----------|
| å¿«é€Ÿæ’åº | O(n log n) | O(n log n) | O(nÂ²) |
| å½’å¹¶æ’åº | O(n log n) | O(n log n) | O(n log n) |
| å†’æ³¡æ’åº | O(n) | O(nÂ²) | O(nÂ²) |

Masterå®šç†ï¼š$T(n) = aT(n/b) + f(n)$

å…¶ä¸­ $a \\geq 1, b > 1$ æ˜¯å¸¸æ•°ï¼Œ$f(n)$ æ˜¯æ­£å‡½æ•°ã€‚''',
            "groundtruth_content_list": [
                {"type": "heading", "content": "ç®—æ³•å¤æ‚åº¦åˆ†æ", "level": 1},
                {"type": "paragraph", "content": "è¿™é‡Œä»‹ç»å¸¸è§ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ã€‚"},
                {"type": "heading", "content": "å¿«é€Ÿæ’åºå®ç°", "level": 2},
                {"type": "code", "content": "def quicksort(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x < pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x > pivot]\n    \n    return quicksort(left) + middle + quicksort(right)"},
                {"type": "heading", "content": "å¤æ‚åº¦å¯¹æ¯”", "level": 2},
                {"type": "table", "content": "| ç®—æ³• | æœ€å¥½æƒ…å†µ | å¹³å‡æƒ…å†µ | æœ€åæƒ…å†µ |\n|------|----------|----------|----------|\n| å¿«é€Ÿæ’åº | O(n log n) | O(n log n) | O(nÂ²) |\n| å½’å¹¶æ’åº | O(n log n) | O(n log n) | O(n log n) |\n| å†’æ³¡æ’åº | O(n) | O(nÂ²) | O(nÂ²) |"},
                {"type": "equation-inline", "content": "T(n) = aT(n/b) + f(n)"},
                {"type": "paragraph", "content": "å…¶ä¸­ a â‰¥ 1, b > 1 æ˜¯å¸¸æ•°ï¼Œf(n) æ˜¯æ­£å‡½æ•°ã€‚"}
            ],
            "url": "https://algorithm-guide.cs.edu/complexity-analysis",
            "layout_id": "algorithm-guide_4",
            "max_layer_n": 14,
            "url_host_name": "algorithm-guide.cs.edu",
            "raw_warc_path": "s3://cc-raw-computer-science/crawl-data/CC-MAIN-2025-13/segments/1742004433093.21/warc/algo-004.warc.gz",
            "language": "zh",
            "__dom_depth": 16,
            "__dom_width": 7320,
            "__type": "__computer_science",
            "__tag": "ALGORITHM_CONTENT",
            "marked_type": "normal",
            "content_type": "computer_science"
        }
    ]
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = BenchmarkDataset(name="sample_dataset", description="ç¤ºä¾‹è¯„æµ‹æ•°æ®é›†")
    
    for sample_data in samples:
        sample = DataSample.from_dict(sample_data)
        dataset.add_sample(sample)
    
    return dataset


def demo_basic_mock_evaluation():
    """æ¼”ç¤ºåŸºæœ¬è¯„æµ‹æµç¨‹"""
    
    print("=== WebMainBench åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹ ===\n")
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(level="INFO")
    
    # 1. åˆ›å»ºæˆ–åŠ è½½æ•°æ®é›†
    print("1. åˆ›å»ºç¤ºä¾‹æ•°æ®é›†...")
    dataset = create_sample_dataset()
    print(f"æ•°æ®é›†åŒ…å« {len(dataset)} ä¸ªæ ·æœ¬")
    print(f"æ•°æ®é›†ç»Ÿè®¡: {dataset.get_statistics()}\n")
    
    # 2. ä¿å­˜æ•°æ®é›†åˆ°æ–‡ä»¶
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    dataset_path = data_dir / "sample_dataset.jsonl"
    DataSaver.save_jsonl(dataset, dataset_path, include_results=False)
    print(f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {dataset_path}\n")
    
    # 3. é‡æ–°åŠ è½½æ•°æ®é›†
    print("2. é‡æ–°åŠ è½½æ•°æ®é›†...")
    loaded_dataset = DataLoader.load_jsonl(dataset_path)
    print(f"åŠ è½½çš„æ•°æ®é›†åŒ…å« {len(loaded_dataset)} ä¸ªæ ·æœ¬\n")
    
    # 4. åˆ—å‡ºå¯ç”¨çš„æŠ½å–å™¨
    print("3. å¯ç”¨çš„æŠ½å–å™¨:")
    available_extractors = ExtractorFactory.list_available()
    for extractor_name in available_extractors:
        print(f"  - {extractor_name}")
    print()
    
    # 5. åˆ›å»ºè¯„æµ‹å™¨
    print("4. åˆ›å»ºè¯„æµ‹å™¨...")
    evaluator = Evaluator()
    print(f"å¯ç”¨çš„è¯„æµ‹æŒ‡æ ‡: {evaluator.metric_calculator.list_available_metrics()}\n")
    
    # 6. åˆ›å»ºä¸€ä¸ªæ¨¡æ‹ŸæŠ½å–å™¨è¿›è¡Œæ¼”ç¤º
    print("5. åˆ›å»ºæ¨¡æ‹ŸæŠ½å–å™¨...")
    
    from webmainbench.extractors import BaseExtractor, ExtractionResult
    
    class MockExtractor(BaseExtractor):
        """æ¨¡æ‹ŸæŠ½å–å™¨ï¼Œç”¨äºæ¼”ç¤º"""
        
        def _setup(self):
            pass
        
        def _extract_content(self, html, url=None):
            # ç®€å•çš„æ¨¡æ‹ŸæŠ½å–é€»è¾‘
            if "æ ‡é¢˜" in html:
                content = "# æå–çš„æ ‡é¢˜\n\næå–çš„æ­£æ–‡å†…å®¹ã€‚"
                content_list = [
                    {"type": "heading", "content": "æå–çš„æ ‡é¢˜", "level": 1},
                    {"type": "paragraph", "content": "æå–çš„æ­£æ–‡å†…å®¹ã€‚"}
                ]
            else:
                content = "æå–çš„å†…å®¹"
                content_list = [{"type": "paragraph", "content": "æå–çš„å†…å®¹"}]
            
            return ExtractionResult(
                content=content,
                content_list=content_list,
                success=True,
                confidence_score=0.85
            )
    
    # æ³¨å†Œæ¨¡æ‹ŸæŠ½å–å™¨
    ExtractorFactory.register("mock", MockExtractor)
    mock_extractor = ExtractorFactory.create("mock")
    print("æ¨¡æ‹ŸæŠ½å–å™¨å·²åˆ›å»º\n")
    
    # 7. è¿è¡Œè¯„æµ‹
    print("6. è¿è¡Œè¯„æµ‹...")
    result = evaluator.evaluate(
        dataset=loaded_dataset,
        extractor=mock_extractor,
        max_samples=2  # é™åˆ¶æ ·æœ¬æ•°é‡ç”¨äºæ¼”ç¤º
    )
    
    # 8. æ˜¾ç¤ºç»“æœ
    print("\n7. è¯„æµ‹ç»“æœ:")
    print("=" * 50)
    formatted_results = format_results(result.to_dict())
    print(formatted_results)
    
    # 9. ä¿å­˜ç»“æœ
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)
    
    results_path = results_dir / "mock_evaluation_results.json"
    DataSaver.save_evaluation_results(result, results_path)
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    # 10. ç”ŸæˆæŠ¥å‘Š
    report_path = results_dir / "mock_evaluation_report.csv"
    DataSaver.save_summary_report(result, report_path)
    print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


def demo_extractor_comparison():
    """æ¼”ç¤ºå¤šæŠ½å–å™¨å¯¹æ¯”"""
    
    print("\n=== å¤šæŠ½å–å™¨å¯¹æ¯”æ¼”ç¤º ===\n")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = create_sample_dataset()
    
    # åˆ›å»ºå¤šä¸ªæ¨¡æ‹ŸæŠ½å–å™¨
    from webmainbench.extractors import BaseExtractor, ExtractionResult
    
    class ExtractorA(BaseExtractor):
        def _setup(self):
            pass
        def _extract_content(self, html, url=None):
            return ExtractionResult(
                content="æŠ½å–å™¨Açš„ç»“æœ",
                # content_list=[{"type": "paragraph", "content": "æŠ½å–å™¨Açš„ç»“æœ"}],
                success=True,
                confidence_score=0.9
            )
    
    class ExtractorB(BaseExtractor):
        def _setup(self):
            pass
        def _extract_content(self, html, url=None):
            return ExtractionResult(
                content="æŠ½å–å™¨Bçš„ç»“æœ",
                # content_list=[{"type": "paragraph", "content": "æŠ½å–å™¨Bçš„ç»“æœ"}],
                success=True,
                confidence_score=0.8
            )
    
    # æ³¨å†ŒæŠ½å–å™¨
    ExtractorFactory.register("extractor_a", ExtractorA)
    ExtractorFactory.register("extractor_b", ExtractorB)
    
    # è¿è¡Œå¯¹æ¯”
    evaluator = Evaluator()
    extractors = ["extractor_a", "extractor_b"]
    
    results = evaluator.compare_extractors(
        dataset=dataset,
        extractors=extractors,
        max_samples=2
    )
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print("å¯¹æ¯”ç»“æœ:")
    print("-" * 40)
    for extractor_name, result in results.items():
        overall_score = result.overall_metrics.get('overall', 0)
        print(f"{extractor_name}: {overall_score:.4f}")
    
    # ä¿å­˜å¤šæŠ½å–å™¨å¯¹æ¯”æ¦œå•
    all_results = []
    for extractor_name, result in results.items():
        all_results.append(result.to_dict())
    
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)
    leaderboard_path = results_dir / "leaderboard.csv"
    DataSaver.save_summary_report(all_results, leaderboard_path)
    print(f"\nğŸ“Š æ¦œå•å·²ä¿å­˜åˆ°: {leaderboard_path}")


def demo_llm_webkit_evaluation():
    """æ¼”ç¤ºLLM-WebKitæŠ½å–å™¨çš„6é¡¹æŒ‡æ ‡è¯„æµ‹"""
    
    print("=== LLM-WebKit Extractor 6é¡¹æŒ‡æ ‡è¯„æµ‹ç¤ºä¾‹ ===\n")
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(level="INFO")
    
    # 1. åˆ›å»ºåŒ…å«å„ç§å†…å®¹ç±»å‹çš„æµ‹è¯•æ•°æ®é›†
    print("1. åˆ›å»ºåŒ…å«å¤šç§å†…å®¹ç±»å‹çš„æµ‹è¯•æ•°æ®é›†...")
    
    samples = []
    
    # æ ·æœ¬1: åŒ…å«æ–‡æœ¬å’Œä»£ç 
    samples.append(DataSample(
        id="text_code_sample",
        html="""
        <html>
        <body>
            <h1>Pythonç¼–ç¨‹ç¤ºä¾‹</h1>
            <p>è¿™æ˜¯ä¸€æ®µå…³äºPythonç¼–ç¨‹çš„ä»‹ç»æ–‡æœ¬ã€‚</p>
            <pre><code>
def hello_world():
    print("Hello, World!")
    return True
            </code></pre>
            <p>ä»¥ä¸Šä»£ç å±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„Pythonå‡½æ•°ã€‚</p>
        </body>
        </html>
        """,
        groundtruth_content="""# Pythonç¼–ç¨‹ç¤ºä¾‹

è¿™æ˜¯ä¸€æ®µå…³äºPythonç¼–ç¨‹çš„ä»‹ç»æ–‡æœ¬ã€‚

```python
def hello_world():
    print("Hello, World!")
    return True
```

ä»¥ä¸Šä»£ç å±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„Pythonå‡½æ•°ã€‚""",
        groundtruth_content_list=[
            {"type": "heading", "content": "Pythonç¼–ç¨‹ç¤ºä¾‹", "level": 1},
            {"type": "text", "content": "è¿™æ˜¯ä¸€æ®µå…³äºPythonç¼–ç¨‹çš„ä»‹ç»æ–‡æœ¬ã€‚"},
            {"type": "code", "content": "def hello_world():\n    print(\"Hello, World!\")\n    return True", "language": "python"},
            {"type": "text", "content": "ä»¥ä¸Šä»£ç å±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„Pythonå‡½æ•°ã€‚"}
        ]
    ))
    
    # æ ·æœ¬2: åŒ…å«è¡¨æ ¼
    samples.append(DataSample(
        id="table_sample",
        html="""
        <html>
        <body>
            <h2>é”€å”®æ•°æ®ç»Ÿè®¡</h2>
            <table>
                <thead>
                    <tr>
                        <th>äº§å“</th>
                        <th>é”€é‡</th>
                        <th>æ”¶å…¥</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>äº§å“A</td>
                        <td>100</td>
                        <td>1000</td>
                    </tr>
                    <tr>
                        <td>äº§å“B</td>
                        <td>200</td>
                        <td>3000</td>
                    </tr>
                </tbody>
            </table>
        </body>
        </html>
        """,
        groundtruth_content="""## é”€å”®æ•°æ®ç»Ÿè®¡

| äº§å“ | é”€é‡ | æ”¶å…¥ |
|------|------|------|
| äº§å“A | 100 | 1000 |
| äº§å“B | 200 | 3000 |""",
        groundtruth_content_list=[
            {"type": "heading", "content": "é”€å”®æ•°æ®ç»Ÿè®¡", "level": 2},
            {"type": "table", "content": "| äº§å“ | é”€é‡ | æ”¶å…¥ |\n|------|------|------|\n| äº§å“A | 100 | 1000 |\n| äº§å“B | 200 | 3000 |"}
        ]
    ))
    
    # æ ·æœ¬3: åŒ…å«å…¬å¼
    samples.append(DataSample(
        id="formula_sample",
        html="""
        <html>
        <body>
            <h2>æ•°å­¦å…¬å¼ç¤ºä¾‹</h2>
            <p>è¿™æ˜¯ä¸€ä¸ªè¡Œå†…å…¬å¼: $E = mc^2$</p>
            <p>è¿™æ˜¯ä¸€ä¸ªè¡Œé—´å…¬å¼:</p>
            <div>$$\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}$$</div>
        </body>
        </html>
        """,
        groundtruth_content="""## æ•°å­¦å…¬å¼ç¤ºä¾‹

è¿™æ˜¯ä¸€ä¸ªè¡Œå†…å…¬å¼: $E = mc^2$

è¿™æ˜¯ä¸€ä¸ªè¡Œé—´å…¬å¼:

$$\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}$$""",
        groundtruth_content_list=[
            {"type": "heading", "content": "æ•°å­¦å…¬å¼ç¤ºä¾‹", "level": 2},
            {"type": "text", "content": "è¿™æ˜¯ä¸€ä¸ªè¡Œå†…å…¬å¼: $E = mc^2$"},
            {"type": "text", "content": "è¿™æ˜¯ä¸€ä¸ªè¡Œé—´å…¬å¼:"},
            {"type": "formula", "content": "\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}"}
        ]
    ))
    
    # åˆ›å»ºæ•°æ®é›†å¹¶æ·»åŠ æ ·æœ¬
    dataset = BenchmarkDataset(name="llm_webkit_test", description="LLM-WebKit 6é¡¹æŒ‡æ ‡æµ‹è¯•æ•°æ®é›†")
    for sample in samples:
        dataset.add_sample(sample)
    
    print(f"æµ‹è¯•æ•°æ®é›†åŒ…å« {len(dataset)} ä¸ªæ ·æœ¬")
    print(f"æ ·æœ¬ç±»å‹: æ–‡æœ¬+ä»£ç , è¡¨æ ¼, å…¬å¼\n")
    
    # 2. åˆ›å»ºLLM-WebKitæŠ½å–å™¨
    print("2. åˆ›å»ºLLM-WebKitæŠ½å–å™¨...")
    
    # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æŠ½å–å™¨
    available_extractors = ExtractorFactory.list_available()
    print(f"å¯ç”¨çš„æŠ½å–å™¨: {available_extractors}")
    
    # ç›´æ¥åˆ›å»ºLLM-WebKitæŠ½å–å™¨ï¼Œè®¾ç½®æ¨¡å‹è·¯å¾„
    config = {
        "model_path": "/Users/chupei/model/checkpoint-3296"
    }
    extractor = ExtractorFactory.create("llm-webkit", config=config)
    print(f"âœ… LLM-WebKitæŠ½å–å™¨åˆ›å»ºæˆåŠŸï¼Œæ¨¡å‹è·¯å¾„: {config['model_path']}")
    
    print()
    
    # 3. åˆ›å»ºè¯„æµ‹å™¨å¹¶æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æŒ‡æ ‡
    print("3. åˆ›å»ºè¯„æµ‹å™¨...")
    evaluator = Evaluator()
    available_metrics = evaluator.metric_calculator.list_available_metrics()
    print(f"âœ… å¯ç”¨çš„è¯„æµ‹æŒ‡æ ‡ ({len(available_metrics)}é¡¹):")
    
    # æŒ‰ç…§6é¡¹æŒ‡æ ‡åˆ†ç±»æ˜¾ç¤º
    target_metrics = ["overall", "text_edit", "code_edit", "table_edit", "table_TEDS", "formula_edit"]
    
    for metric in target_metrics:
        if metric in available_metrics:
            print(f"  âœ… {metric}")
        else:
            print(f"  âŒ {metric} (æœªæ³¨å†Œ)")
    
    print()
    
    # 4. è¿è¡Œè¯„æµ‹
    print("4. å¼€å§‹è¯„æµ‹...")
    print("=" * 60)
    
    result = evaluator.evaluate(
        dataset=dataset,
        extractor=extractor,
        max_samples=None  # è¯„æµ‹æ‰€æœ‰æ ·æœ¬
    )
    
    # 5. æ˜¾ç¤ºè¯¦ç»†çš„6é¡¹æŒ‡æ ‡ç»“æœ
    print("\n5. ğŸ“Š 6é¡¹æŒ‡æ ‡è¯¦ç»†è¯„æµ‹ç»“æœ:")
    print("=" * 60)
    
    results_dict = result.to_dict()
    
    # ä»overall_metricsä¸­æå–æŒ‡æ ‡ç»“æœ
    metrics = results_dict.get('overall_metrics', {})
    
    # æŒ‰ç…§æŒ‡æ ‡åˆ†ç±»æ˜¾ç¤º
    print(f"\nğŸ† ç»¼åˆæŒ‡æ ‡:")
    if 'overall' in metrics:
        print(f"  overall (ç»¼åˆå¾—åˆ†): {metrics['overall']:.4f}")
    else:
        print("  overall: æœªè®¡ç®—")
    
    print(f"\nğŸ“ æ–‡æœ¬ç›¸å…³æŒ‡æ ‡:")
    if 'text_edit' in metrics:
        print(f"  text_edit (æ–‡æœ¬ç¼–è¾‘è·ç¦»): {metrics['text_edit']:.4f}")
    else:
        print("  text_edit: æœªè®¡ç®—")
    if 'code_edit' in metrics:
        print(f"  code_edit (ä»£ç ç¼–è¾‘è·ç¦»): {metrics['code_edit']:.4f}")
    else:
        print("  code_edit: æœªè®¡ç®—")
    
    print(f"\nğŸ“Š è¡¨æ ¼ç›¸å…³æŒ‡æ ‡:")
    if 'table_edit' in metrics:
        print(f"  table_edit (è¡¨æ ¼ç¼–è¾‘è·ç¦»): {metrics['table_edit']:.4f}")
    else:
        print("  table_edit: æœªè®¡ç®—")
    if 'table_TEDS' in metrics:
        print(f"  table_TEDS (è¡¨æ ¼ç»“æ„ç›¸ä¼¼åº¦): {metrics['table_TEDS']:.4f}")
    else:
        print("  table_TEDS: æœªè®¡ç®—")
    
    print(f"\nğŸ§® å…¬å¼ç›¸å…³æŒ‡æ ‡:")
    if 'formula_edit' in metrics:
        print(f"  formula_edit (å…¬å¼ç¼–è¾‘è·ç¦»): {metrics['formula_edit']:.4f}")
    else:
        print("  formula_edit: æœªè®¡ç®—")
    
    print(f"\nğŸ“ˆ è¯¦ç»†ç»Ÿè®¡:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(dataset)}")
    success_count = len([s for s in results_dict.get('sample_results', []) if s.get('extraction_success', False)])
    failure_count = len(dataset) - success_count
    print(f"  æˆåŠŸæ ·æœ¬æ•°: {success_count}")
    print(f"  å¤±è´¥æ ·æœ¬æ•°: {failure_count}")
    
    # 6. ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    print("\n" + "=" * 60)
    print("6. ä¿å­˜è¯„æµ‹ç»“æœ...")
    
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    results_path = results_dir / "llm_webkit_evaluation_results.json"
    DataSaver.save_evaluation_results(result, results_path)  # ç›´æ¥ä¼ é€’resultå¯¹è±¡
    print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    # ç”ŸæˆCSVæŠ¥å‘Š
    report_path = results_dir / "llm_webkit_evaluation_report.csv"
    DataSaver.save_summary_report(result, report_path)  # ç›´æ¥ä¼ é€’resultå¯¹è±¡
    print(f"âœ… CSVæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    print("\n" + "=" * 60)
    print("âœ… LLM-WebKit 6é¡¹æŒ‡æ ‡è¯„æµ‹å®Œæˆï¼")


def demo_dataset_with_extraction():
    """æ¼”ç¤ºä¿å­˜å¸¦æœ‰æŠ½å–å†…å®¹çš„æ•°æ®é›†"""
    print("=== æ¼”ç¤ºï¼šä¿å­˜å¸¦æœ‰æŠ½å–å†…å®¹çš„æ•°æ®é›† ===")
    
    from webmainbench import DataLoader, DataSaver, Evaluator, ExtractorFactory
    from pathlib import Path
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    data_dir = Path("data")
    dataset_path = data_dir / "sample_dataset.jsonl"
    # dataset_path = "/Users/chupei/Downloads/WebMainBench_dataset_merge_2549.jsonl"
    
    print(f"ğŸ“‚ æ•°æ®é›†æ–‡ä»¶: {dataset_path}")
    
    # ğŸ”§ åˆ›å»ºllm-webkitæŠ½å–å™¨ï¼ˆç»Ÿä¸€ä½¿ç”¨ï¼‰
    extractor_config = {"model_path": "/Users/chupei/model/checkpoint-3296"}
    extractor = ExtractorFactory.create("llm-webkit", config=extractor_config)
    print(f"ğŸ¤– ä½¿ç”¨æŠ½å–å™¨: {extractor.name}")
    
    # åˆ›å»ºè¯„æµ‹å™¨
    evaluator = Evaluator()
    
    # ğŸ”§ é€‰æ‹©è¯„æµ‹æ¨¡å¼ï¼šå†…å­˜æ¨¡å¼ vs æ‰¹å¤„ç†æ¨¡å¼
    USE_BATCHED_MODE = True  # è®¾ç½®ä¸ºTrueä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼ˆé€‚ç”¨äºå¤§æ•°æ®é›†ï¼‰
    
    if USE_BATCHED_MODE:
        print("ğŸ”„ ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰")
        
        # ğŸš€ æ‰¹å¤„ç†è¯„æµ‹ï¼ˆé€‚ç”¨äºå¤§æ•°æ®é›†ï¼‰
        result = evaluator.evaluate_batched(
            jsonl_file_path=dataset_path,
            extractor=extractor,  # ç›´æ¥ä¼ é€’extractorå¯¹è±¡
            batch_size=10,        # å°æ‰¹æ¬¡
            max_samples=20        # æ¼”ç¤ºç”¨
        )
        print(f"âœ… æ‰¹å¤„ç†è¯„æµ‹å®Œæˆï¼Œæ€»ä½“å¾—åˆ†: {result.overall_metrics.get('overall', 0):.4f}")
        
        # ä¸ºäº†ä¿å­˜å¸¦æœ‰æŠ½å–å†…å®¹çš„æ•°æ®é›†ï¼Œéœ€è¦é‡æ–°åŠ è½½åŸå§‹æ•°æ®é›†
        # æ³¨ï¼šè¿™é‡Œåªæ˜¯çŸ­æš‚åŠ è½½ç”¨äºä¿å­˜ï¼Œä¸å½±å“å‰é¢çš„å†…å­˜ä¼˜åŒ–è¯„æµ‹
        dataset = DataLoader.load_jsonl(dataset_path, include_results=False)
        dataset.name = result.dataset_name
            
    else:
        print("ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿå†…å­˜æ¨¡å¼")
        
        # ä»æ–‡ä»¶åŠ è½½æ•°æ®é›†
        print(f"ğŸ“‚ ä»æ–‡ä»¶åŠ è½½æ•°æ®é›†: {dataset_path}")
        dataset = DataLoader.load_jsonl(dataset_path, include_results=False)
        dataset.name = "WebMainBench_with_extraction"
        dataset.description = "æ¼”ç¤ºæŠ½å–å†…å®¹ä¿å­˜çš„æµ‹è¯•æ•°æ®é›†"
        
        print(f"ğŸ“Š åŠ è½½æ•°æ®é›†å®Œæˆï¼ŒåŒ…å« {len(dataset.samples)} ä¸ªæ ·æœ¬")
        
        # è¿è¡Œè¯„æµ‹
        result = evaluator.evaluate(dataset, extractor)
    
    print(f"âœ… è¯„æµ‹å®Œæˆï¼Œæ€»ä½“å¾—åˆ†: {result.overall_metrics.get('overall', 0):.4f}")
    
    # ä¿å­˜å¸¦æœ‰æŠ½å–å†…å®¹çš„æ•°æ®é›†
    results_dir = Path("results")
    enriched_dataset_path = results_dir / f"{dataset.name}_with_{extractor.name}_extraction.jsonl"
    
    DataSaver.save_dataset_with_extraction(
        results=result,
        dataset=dataset, 
        file_path=enriched_dataset_path,
        extractor_name=extractor.name
    )
    
    print(f"ğŸ’¾ å·²ä¿å­˜å¸¦æœ‰æŠ½å–å†…å®¹çš„æ•°æ®é›†åˆ°: {enriched_dataset_path}")
    
    # ä¿å­˜è¯„æµ‹ç»“æœå’Œæ‘˜è¦æŠ¥å‘Š
    evaluation_results_path = results_dir / f"{dataset.name}_{extractor.name}_evaluation_results.json"
    summary_report_path = results_dir / f"{dataset.name}_{extractor.name}_evaluation_report.csv"
    
    DataSaver.save_evaluation_results(result, evaluation_results_path)
    DataSaver.save_summary_report(result, summary_report_path)
    
    print(f"ğŸ“Š å·²ä¿å­˜è¯„æµ‹ç»“æœåˆ°: {evaluation_results_path}")
    print(f"ğŸ“ˆ å·²ä¿å­˜æ‘˜è¦æŠ¥å‘Šåˆ°: {summary_report_path}")
    
    # æ˜¾ç¤ºä¿å­˜çš„å­—æ®µä¿¡æ¯
    print("\nğŸ“‹ ä¿å­˜çš„æ–°å­—æ®µåŒ…æ‹¬:")
    print(f"  - {extractor.name}_content: æŠ½å–çš„å†…å®¹")
    print(f"  - {extractor.name}_content_list: æŠ½å–çš„ç»“æ„åŒ–å†…å®¹åˆ—è¡¨")
    print(f"  - {extractor.name}_success: æŠ½å–æ˜¯å¦æˆåŠŸ")
    print(f"  - {extractor.name}_time: æŠ½å–è€—æ—¶")
    print(f"  - {extractor.name}_*_score: å„é¡¹æŒ‡æ ‡åˆ†æ•°")


def demo_multi_extraction():
    """æ¼”ç¤ºä¿å­˜å¸¦æœ‰å¤šä¸ªæŠ½å–å™¨æŠ½å–å†…å®¹çš„æ•°æ®é›†ï¼ˆæ”¯æŒæ‰¹å¤„ç†æ¨¡å¼ï¼‰"""
    print("=== æ¼”ç¤ºï¼šä¿å­˜å¸¦æœ‰å¤šä¸ªæŠ½å–å™¨æŠ½å–å†…å®¹çš„æ•°æ®é›† ===")

    from webmainbench import DataLoader, DataSaver, Evaluator, ExtractorFactory
    from pathlib import Path
    import time


    # è®¾ç½®æ—¥å¿—
    setup_logging(level="INFO")

    # é…ç½®æ–‡ä»¶è·¯å¾„
    data_dir = Path("../data")
    # dataset_path = data_dir / "sample_dataset.jsonl"
    dataset_path = "/home/lulindong/Pycharm_projects/cc/WebMainBench_llm-webkit_v1_WebMainBench_dataset_merge_with_llm_webkit.jsonl"

    print(f"ğŸ“‚ æ•°æ®é›†æ–‡ä»¶: {dataset_path}")

    # ğŸ”§ å®šä¹‰è¦ä½¿ç”¨çš„æŠ½å–å™¨åˆ—è¡¨åŠé…ç½®
    extractors_info = [
        {"name": "resiliparse", "config": {
            "main_content": True,
            "alt_texts": True,
            "links": False,
            "list_bullets": True,
            "preserve_formatting": True
        }},
        {"name": "trafilatura", "config": {}},
        {"name": "magic-html", "config": {}},
    ]

    # ğŸ”§ é€‰æ‹©è¯„æµ‹æ¨¡å¼ï¼šå†…å­˜æ¨¡å¼ vs æ‰¹å¤„ç†æ¨¡å¼
    USE_BATCHED_MODE = True  # å¤§æ•°æ®é›†å»ºè®®è®¾ä¸ºTrue
    BATCH_SIZE = 10  # æ‰¹å¤„ç†å¤§å°
    MAX_SAMPLES = None  # æ¼”ç¤ºç”¨ï¼ˆå…¨é‡è¯„æµ‹å¯è®¾ä¸ºNoneï¼‰

    # åˆ›å»ºç»“æœç›®å½•
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)

    # å­˜å‚¨æ‰€æœ‰æŠ½å–å™¨çš„è¯„æµ‹ç»“æœå’Œæ€§èƒ½æ•°æ®
    all_results = []
    extractor_performance = []

    # ä¸ºæ¯ä¸ªæŠ½å–å™¨è¿è¡Œè¯„æµ‹
    for info in extractors_info:
        extractor_name = info["name"]
        config = info["config"]

        try:
            # åˆ›å»ºæŠ½å–å™¨å®ä¾‹
            extractor = ExtractorFactory.create(extractor_name, config=config)
            print(f"\nğŸ¤– ä½¿ç”¨æŠ½å–å™¨: {extractor.name}")
        except Exception as e:
            print(f"âš ï¸ {extractor_name} æŠ½å–å™¨åˆ›å»ºå¤±è´¥: {e}")
            continue

        # è®°å½•æ€»è€—æ—¶
        start_time = time.time()

        # åˆå§‹åŒ–è¯„æµ‹å™¨
        evaluator = Evaluator()

        # é€‰æ‹©æ‰¹å¤„ç†æ¨¡å¼æˆ–ä¼ ç»Ÿæ¨¡å¼
        if USE_BATCHED_MODE:
            print(f"ğŸ”„ ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼ˆæ‰¹å¤§å°: {BATCH_SIZE}ï¼Œæœ€å¤§æ ·æœ¬: {MAX_SAMPLES or 'å…¨éƒ¨'}ï¼‰")
            # æ‰¹å¤„ç†è¯„æµ‹ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰
            result = evaluator.evaluate_batched(
                jsonl_file_path=dataset_path,
                extractor=extractor,
                batch_size=BATCH_SIZE,
                max_samples=MAX_SAMPLES
            )
            # ä¸ºä¿å­˜æ•°æ®é›†ï¼Œä¸´æ—¶åŠ è½½åŸå§‹æ•°æ®ï¼ˆä¸å½±å“å†…å­˜ä¼˜åŒ–ï¼‰
            dataset = DataLoader.load_jsonl(dataset_path, include_results=False, max_samples=MAX_SAMPLES)
            dataset.name = result.dataset_name
        else:
            print("ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿå†…å­˜æ¨¡å¼")
            # åŠ è½½å®Œæ•´æ•°æ®é›†åˆ°å†…å­˜
            dataset = DataLoader.load_jsonl(dataset_path, include_results=False, max_samples=MAX_SAMPLES)
            dataset.name = "WebMainBench_with_multi_extraction"
            dataset.description = "å¤šæŠ½å–å™¨å†…å®¹ä¿å­˜æ¼”ç¤ºæ•°æ®é›†"
            print(f"ğŸ“Š åŠ è½½æ•°æ®é›†å®Œæˆï¼ŒåŒ…å« {len(dataset.samples)} ä¸ªæ ·æœ¬")

            # ä¼ ç»Ÿæ¨¡å¼è¯„æµ‹
            result = evaluator.evaluate(dataset, extractor)

        # è®¡ç®—è€—æ—¶æŒ‡æ ‡
        total_time = time.time() - start_time
        total_samples = len(dataset.samples)
        avg_time_per_sample = total_time / total_samples if total_samples else 0

        # ä¿å­˜æ€§èƒ½æ•°æ®
        extractor_performance.append({
            "name": extractor_name,
            "total_samples": total_samples,
            "total_time": total_time,
            "avg_time_per_sample": avg_time_per_sample
        })

        # è¾“å‡ºè¯„æµ‹ç»“æœ
        print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.4f}ç§’ï¼ˆå•æ ·æœ¬å¹³å‡: {avg_time_per_sample:.4f}ç§’ï¼‰")
        print(f"ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡:")
        print(f"   code_edit: {result.overall_metrics.get('code_edit', 0):.4f}")
        print(f"   formula_edit: {result.overall_metrics.get('formula_edit', 0):.4f}")
        print(f"   table_TEDS: {result.overall_metrics.get('table_TEDS', 0):.4f}")
        print(f"   table_edit: {result.overall_metrics.get('table_edit', 0):.4f}")
        print(f"   text_edit: {result.overall_metrics.get('text_edit', 0):.4f}")
        print(f"âœ… æ€»ä½“å¾—åˆ†: {result.overall_metrics.get('overall', 0):.4f}")

        all_results.append(result)

        # ä¿å­˜å¸¦æœ‰å½“å‰æŠ½å–å™¨å†…å®¹çš„æ•°æ®é›†
        enriched_dataset_path = results_dir / f"{dataset.name}_{extractor.name}_extraction_infer.jsonl"
        DataSaver.save_dataset_with_extraction(
            results=result,
            dataset=dataset,
            file_path=enriched_dataset_path,
            extractor_name=extractor.name
        )
        print(f"ğŸ’¾ å·²ä¿å­˜æŠ½å–å†…å®¹åˆ°: {enriched_dataset_path}")

        # ä¿å­˜å•ä¸ªæŠ½å–å™¨çš„è¯„æµ‹ç»“æœ
        eval_results_path = results_dir / f"{dataset.name}_{extractor.name}_evaluation_results.json"
        DataSaver.save_evaluation_results(result, eval_results_path)
        print(f"ğŸ“‹ å·²ä¿å­˜è¯„æµ‹ç»“æœåˆ°: {eval_results_path}")

    # ä¿å­˜æ‰€æœ‰æŠ½å–å™¨çš„æ±‡æ€»æŠ¥å‘Š
    if all_results:
        summary_path = results_dir / f"{dataset.name}_multi_extractors_summary_report.csv"
        DataSaver.save_summary_report(all_results, summary_path)
        print(f"\nğŸ“ˆ å·²ä¿å­˜æ±‡æ€»æŠ¥å‘Šåˆ°: {summary_path}")

    # å±•ç¤ºæ€§èƒ½å¯¹æ¯”
    if extractor_performance:
        print("\nâš¡ æŠ½å–å™¨æ€§èƒ½å¯¹æ¯”:")
        for perf in extractor_performance:
            print(f"  {perf['name']}:")
            print(f"    æ ·æœ¬æ•°: {perf['total_samples']}")
            print(f"    æ€»è€—æ—¶: {perf['total_time']:.4f}ç§’")
            print(f"    å•æ ·æœ¬è€—æ—¶: {perf['avg_time_per_sample']:.4f}ç§’")
            print(f"    æ•ˆç‡: {1 / perf['avg_time_per_sample']:.2f}æ ·æœ¬/ç§’")

    # å±•ç¤ºä¿å­˜çš„å­—æ®µä¿¡æ¯
    print("\nğŸ“‹ ä¿å­˜çš„æ–°å­—æ®µè¯´æ˜:")
    for info in extractors_info:
        name = info["name"]
        print(f"  {name}ç›¸å…³å­—æ®µ:")
        print(f"    - {name}_content: æŠ½å–çš„åŸå§‹å†…å®¹")
        print(f"    - {name}_content_list: ç»“æ„åŒ–å†…å®¹åˆ—è¡¨ï¼ˆå«typeå­—æ®µï¼‰")
        print(f"    - {name}_success: æŠ½å–æ˜¯å¦æˆåŠŸï¼ˆå¸ƒå°”å€¼ï¼‰")
        print(f"    - {name}_time: å•æ ·æœ¬æŠ½å–è€—æ—¶ï¼ˆç§’ï¼‰")
        print(f"    - {name}_*_score: å„æŒ‡æ ‡å¾—åˆ†ï¼ˆå¦‚{name}_text_editï¼‰")


def demo_llm_webkit_with_preprocessed_html_evaluation():
    """æ¼”ç¤ºLLM-WebKité¢„å¤„ç†HTMLåŠŸèƒ½çš„è¯„æµ‹"""
    
    print("\n=== LLM-WebKit é¢„å¤„ç†HTMLåŠŸèƒ½æ¼”ç¤º ===\n")
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(level="INFO")
    
    # 1. åˆ›å»ºåŒ…å«é¢„å¤„ç†HTMLçš„æµ‹è¯•æ•°æ®é›†
    print("1. åˆ›å»ºåŒ…å«é¢„å¤„ç†HTMLçš„æµ‹è¯•æ•°æ®é›†...")
    
    samples = []
    
    # æ ·æœ¬1: åŒ…å«é¢„å¤„ç†çš„HTMLï¼ˆæ¨¡æ‹Ÿç¬¬ä¸€é˜¶æ®µLLMç®€åŒ–åçš„ç»“æœï¼‰
    sample_1_data = {
        "id": "preprocessed_sample_1",
        "html": """<html><body><h1>åŸå§‹å¤æ‚HTML</h1><p>è¿™é‡Œæ˜¯åŸå§‹çš„å¤æ‚HTMLå†…å®¹...</p></body></html>""",
        # è¿™æ˜¯å…³é”®ï¼šåŒ…å«llm_webkit_htmlå­—æ®µï¼ˆé¢„å¤„ç†åçš„ç®€åŒ–HTMLï¼‰
        "llm_webkit_html": """
        <div _item_id="1">
            <h1>æ·±åº¦å­¦ä¹ åŸºç¡€æ•™ç¨‹</h1>
            <p>æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œé€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨å¾ã€‚</p>
        </div>
        <div _item_id="2">
            <h2>æ ¸å¿ƒæ¦‚å¿µ</h2>
            <p>ç¥ç»ç½‘ç»œç”±å¤šä¸ªå±‚ç»„æˆï¼Œæ¯å±‚åŒ…å«å¤šä¸ªç¥ç»å…ƒã€‚</p>
        </div>
        <div _item_id="3">
            <pre><code class="language-python">
import torch
import torch.nn as nn

class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(784, 10)
    
    def forward(self, x):
        return self.fc(x)
            </code></pre>
        </div>
        """,
        "groundtruth_content": """# æ·±åº¦å­¦ä¹ åŸºç¡€æ•™ç¨‹

æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œé€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨å¾ã€‚

## æ ¸å¿ƒæ¦‚å¿µ

ç¥ç»ç½‘ç»œç”±å¤šä¸ªå±‚ç»„æˆï¼Œæ¯å±‚åŒ…å«å¤šä¸ªç¥ç»å…ƒã€‚

```python
import torch
import torch.nn as nn

class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(784, 10)
    
    def forward(self, x):
        return self.fc(x)
```""",
        "groundtruth_content_list": [
            {"type": "heading", "content": "æ·±åº¦å­¦ä¹ åŸºç¡€æ•™ç¨‹", "level": 1},
            {"type": "paragraph", "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œé€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨å¾ã€‚"},
            {"type": "heading", "content": "æ ¸å¿ƒæ¦‚å¿µ", "level": 2},
            {"type": "paragraph", "content": "ç¥ç»ç½‘ç»œç”±å¤šä¸ªå±‚ç»„æˆï¼Œæ¯å±‚åŒ…å«å¤šä¸ªç¥ç»å…ƒã€‚"},
            {"type": "code", "content": "import torch\nimport torch.nn as nn\n\nclass SimpleNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc = nn.Linear(784, 10)\n    \n    def forward(self, x):\n        return self.fc(x)", "language": "python"}
        ]
    }
    # samples.append(DataSample.from_dict(sample_1_data))
    
    # æ ·æœ¬2: åŒ…å«è¡¨æ ¼çš„é¢„å¤„ç†HTML
    sample_2_data = {
        "id": "preprocessed_sample_2", 
        "html": """<html><body><h1>åŸå§‹è¡¨æ ¼é¡µé¢</h1><table>...</table></body></html>""",
        "llm_webkit_html": """
        <div _item_id="1">
            <h1>æ¨¡å‹æ€§èƒ½å¯¹æ¯”</h1>
            <p>ä»¥ä¸‹æ˜¯ä¸åŒæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨CIFAR-10æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼š</p>
        </div>
        <div _item_id="2">
            <table>
                <thead>
                    <tr>
                        <th>æ¨¡å‹</th>
                        <th>å‡†ç¡®ç‡</th>
                        <th>å‚æ•°é‡</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>ResNet-18</td>
                        <td>95.3%</td>
                        <td>11.7M</td>
                    </tr>
                    <tr>
                        <td>VGG-16</td>
                        <td>92.7%</td>
                        <td>138M</td>
                    </tr>
                </tbody>
            </table>
        </div>
        """,
        "groundtruth_content": """# æ¨¡å‹æ€§èƒ½å¯¹æ¯”

ä»¥ä¸‹æ˜¯ä¸åŒæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨CIFAR-10æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼š

| æ¨¡å‹ | å‡†ç¡®ç‡ | å‚æ•°é‡ |
|------|--------|--------|
| ResNet-18 | 95.3% | 11.7M |
| VGG-16 | 92.7% | 138M |""",
        "groundtruth_content_list": [
            {"type": "heading", "content": "æ¨¡å‹æ€§èƒ½å¯¹æ¯”", "level": 1},
            {"type": "paragraph", "content": "ä»¥ä¸‹æ˜¯ä¸åŒæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨CIFAR-10æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼š"},
            {"type": "table", "content": "| æ¨¡å‹ | å‡†ç¡®ç‡ | å‚æ•°é‡ |\n|------|--------|---------|\n| ResNet-18 | 95.3% | 11.7M |\n| VGG-16 | 92.7% | 138M |"}
        ]
    }
    # samples.append(DataSample.from_dict(sample_2_data))
    #
    # # åˆ›å»ºæ•°æ®é›†å¹¶æ·»åŠ æ ·æœ¬
    # dataset = BenchmarkDataset(name="preprocessed_html_test", description="é¢„å¤„ç†HTMLåŠŸèƒ½æµ‹è¯•æ•°æ®é›†")



    # æœ¬åœ°åŠ è½½æ•°æ®é›†
    jsonl_file_path = "/home/lulindong/Pycharm_projects/cc/WebMainBench_llm-webkit_v1_WebMainBench_dataset_merge_with_llm_webkit.jsonl"

    # ä½¿ç”¨DataLoaderåŠ è½½æœ¬åœ°JSONLæ•°æ®
    dataset = DataLoader.load_jsonl(jsonl_file_path)
    for sample in samples:
        dataset.add_sample(sample)
    
    print(f"âœ… æµ‹è¯•æ•°æ®é›†åŒ…å« {len(dataset)} ä¸ªæ ·æœ¬")
    print("ğŸ“‹ æ¯ä¸ªæ ·æœ¬éƒ½åŒ…å«:")
    print("  - html: åŸå§‹å¤æ‚HTML")
    print("  - llm_webkit_html: é¢„å¤„ç†åçš„ç®€åŒ–HTMLï¼ˆåŒ…å«_item_idæ ‡è®°ï¼‰")
    print("  - groundtruth_content: æ ‡å‡†ç­”æ¡ˆ")
    print()
    
    # 2. åˆ›å»ºé¢„å¤„ç†HTMLæ¨¡å¼çš„LLM-WebKitæŠ½å–å™¨
    print("2. åˆ›å»ºé¢„å¤„ç†HTMLæ¨¡å¼çš„LLM-WebKitæŠ½å–å™¨...")
    
    config = {
        "use_preprocessed_html": True,          # ğŸ”‘ å…³é”®é…ç½®ï¼šå¯ç”¨é¢„å¤„ç†HTMLæ¨¡å¼
        "preprocessed_html_field": "llm_webkit_html"  # æŒ‡å®šé¢„å¤„ç†HTMLå­—æ®µå
    }
    
    extractor = ExtractorFactory.create("llm-webkit", config=config)
    print(f"âœ… æŠ½å–å™¨åˆ›å»ºæˆåŠŸ")
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - use_preprocessed_html: {extractor.inference_config.use_preprocessed_html}")
    print(f"  - preprocessed_html_field: {extractor.inference_config.preprocessed_html_field}")
    print(f"  - è·³è¿‡LLMæ¨ç†: æ˜¯ï¼ˆç›´æ¥å¤„ç†é¢„å¤„ç†HTMLï¼‰")
    print()
    
    # 3. æ€§èƒ½å¯¹æ¯”ï¼šå±•ç¤ºé¢„å¤„ç†HTMLæ¨¡å¼çš„ä¼˜åŠ¿
    print("3. æ€§èƒ½ä¼˜åŠ¿æ¼”ç¤º...")
    print("ğŸš€ é¢„å¤„ç†HTMLæ¨¡å¼çš„ä¼˜åŠ¿:")
    print("  âœ… æ— éœ€åŠ è½½å¤§å‹LLMæ¨¡å‹ï¼ˆèŠ‚çœå†…å­˜ï¼‰")
    print("  âœ… è·³è¿‡HTMLç®€åŒ–æ¨ç†æ­¥éª¤ï¼ˆèŠ‚çœæ—¶é—´ï¼‰")
    print("  âœ… åªéœ€è¦åŸºç¡€çš„llm_web_kitä¾èµ–")
    print("  âœ… é€‚åˆæ‰¹é‡å¤„ç†å·²é¢„å¤„ç†çš„æ•°æ®")
    print()
    
    # 4. è¿è¡Œè¯„æµ‹
    print("4. å¼€å§‹è¯„æµ‹...")
    print("=" * 50)
    
    evaluator = Evaluator()
    result = evaluator.evaluate(
        dataset=dataset,
        extractor=extractor,
        max_samples=None
    )
    
    # 5. æ˜¾ç¤ºè¯„æµ‹ç»“æœ
    print("\n5. ğŸ“Š é¢„å¤„ç†HTMLæ¨¡å¼è¯„æµ‹ç»“æœ:")
    print("=" * 50)
    
    results_dict = result.to_dict()
    metrics = results_dict.get('overall_metrics', {})
    
    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    print(f"\nğŸ† ç»¼åˆæŒ‡æ ‡:")
    print(f"  overall: {metrics.get('overall', 0):.4f}")
    
    print(f"\nğŸ“ å†…å®¹æå–è´¨é‡:")
    print(f"  text_edit: {metrics.get('text_edit', 0):.4f}")
    print(f"  code_edit: {metrics.get('code_edit', 0):.4f}")
    print(f"  table_edit: {metrics.get('table_edit', 0):.4f}")
    print(f"  table_TEDS: {metrics.get('table_TEDS', 0):.4f}")
    
    print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
    sample_results = results_dict.get('sample_results', [])
    if sample_results:
        extraction_times = [s.get('extraction_time', 0) for s in sample_results if s.get('extraction_success')]
        if extraction_times:
            avg_time = sum(extraction_times) / len(extraction_times)
            print(f"  å¹³å‡æå–æ—¶é—´: {avg_time:.3f}ç§’")
            print(f"  å¤„ç†é€Ÿåº¦: {1/avg_time:.1f}æ ·æœ¬/ç§’")
    
    success_count = len([s for s in sample_results if s.get('extraction_success', False)])
    print(f"  æˆåŠŸæ ·æœ¬æ•°: {success_count}/{len(dataset)}")
    
    # 6. å±•ç¤ºæ ·æœ¬æå–ç»“æœ
    print(f"\n6. ğŸ“„ æ ·æœ¬æå–ç»“æœé¢„è§ˆ:")
    print("-" * 50)
    
    for i, sample_result in enumerate(sample_results[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ªæ ·æœ¬
        print(f"\næ ·æœ¬ {i+1}: {sample_result.get('sample_id', 'Unknown')}")
        if sample_result.get('extraction_success'):
            content = sample_result.get('extracted_content', '')
            preview = content[:100].replace('\n', ' ') if content else 'æ— å†…å®¹'
            print(f"  âœ… æå–æˆåŠŸ")
            print(f"  ğŸ“ å†…å®¹é¢„è§ˆ: {preview}...")
            print(f"  â±ï¸  æå–æ—¶é—´: {sample_result.get('extraction_time', 0):.3f}ç§’")
        else:
            print(f"  âŒ æå–å¤±è´¥")
    
    # 7. ä¿å­˜ç»“æœ
    print(f"\n7. ğŸ’¾ ä¿å­˜è¯„æµ‹ç»“æœ...")
    
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)
    
    results_path = results_dir / "preprocessed_html_evaluation_results.json"
    report_path = results_dir / "preprocessed_html_evaluation_report.csv"
    
    DataSaver.save_evaluation_results(result, results_path)
    DataSaver.save_summary_report(result, report_path)
    
    print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    print(f"âœ… CSVæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    # 8. ä½¿ç”¨å»ºè®®
    print(f"\n8. ğŸ’¡ å®é™…ä½¿ç”¨å»ºè®®:")
    print("=" * 50)
    print("ğŸ”§ ä½•æ—¶ä½¿ç”¨é¢„å¤„ç†HTMLæ¨¡å¼:")
    print("  1. å·²æœ‰LLMç®€åŒ–åçš„HTMLæ•°æ®")
    print("  2. éœ€è¦æ‰¹é‡å¤„ç†å¤§é‡æ•°æ®")
    print("  3. éƒ¨ç½²ç¯å¢ƒå†…å­˜æœ‰é™")
    print("  4. å¯¹æå–é€Ÿåº¦æœ‰è¾ƒé«˜è¦æ±‚")
    print()
    print("ğŸ“ æ•°æ®å‡†å¤‡è¦æ±‚:")
    print("  1. ç¡®ä¿é¢„å¤„ç†HTMLåŒ…å«_item_idå±æ€§")
    print("  2. ä¿æŒåŸå§‹HTMLä½œä¸ºå¤‡ç”¨")
    print("  3. éªŒè¯é¢„å¤„ç†è´¨é‡")
    print()
    print("âš™ï¸  é…ç½®å‚æ•°è¯´æ˜:")
    print("  - use_preprocessed_html: True/False")
    print("  - preprocessed_html_field: å­—æ®µåï¼ˆé»˜è®¤'llm_webkit_html'ï¼‰")
    
    print("\nâœ… é¢„å¤„ç†HTMLåŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    try:
        # demo_basic_mock_evaluation()
        # demo_llm_webkit_evaluation()  # ä½¿ç”¨LLM-WebKitè¯„æµ‹ç¤ºä¾‹
        demo_llm_webkit_with_preprocessed_html_evaluation()
        # demo_extractor_comparison()
        # demo_dataset_with_extraction()  # æ¼”ç¤ºä¿å­˜å¸¦æœ‰æŠ½å–å†…å®¹çš„æ•°æ®é›†
        # demo_multi_extraction() # æ¼”ç¤ºå¤šä¸ªæŠ½å–å™¨åŒæ—¶è¯„æµ‹
        # demo_lld_workers_extraction()
        print("\nâœ… ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc() 