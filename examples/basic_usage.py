#!/usr/bin/env python3
"""
WebMainBench åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
"""

import json
from pathlib import Path

# å¯¼å…¥ WebMainBench æ¨¡å—
from webmainbench import (
    DataLoader, DataSaver, BenchmarkDataset, DataSample,
    ExtractorFactory, Evaluator, 
    format_results, setup_logging
)


def create_sample_dataset():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®é›†"""
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    samples = [
        {
            "track_id": "0b7f2636-d35f-40bf-9b7f-94be4bcbb396",
            "html": "<html><body><h1 cc-select=\"true\">è¿™æ˜¯æ ‡é¢˜</h1></body></html>",   # äººå·¥æ ‡æ³¨å¸¦cc-select="true" å±æ€§
            "groundtruth_content": "# æ ‡é¢˜\n\næ­£æ–‡å†…å®¹",
            "groundtruth_content_list": [
                {"type": "heading", "content": "æ ‡é¢˜", "level": 1},
                {"type": "paragraph", "content": "æ­£æ–‡å†…å®¹"}
            ],
            "url": "https://orderyourbooks.com/product-category/college-books-p-u/?products-per-page=all",
            "layout_id": "orderyourbooks.com_4",
            "max_layer_n": 10,
            "url_host_name": "orderyourbooks.com",
            "raw_warc_path": "s3://cc-raw-huawei/crawl-data/CC-MAIN-2025-13/segments/1742004433093.21/warc/CC-MAIN-20250319080618-20250319110618-00909.warc.gz?bytes=461610805,172252",
            "language": "en",
            "__dom_depth": 19,
            "__dom_width": 10231,
            "__type": "__max_depth",
            "__tag": "DOM_WIDTH",
            "marked_type": "unwanted",  # normalï¼šæ­£å¸¸æ ‡æ³¨çš„ç½‘é¡µï¼›unableï¼šæ­£æ–‡å†…å®¹æ— æ³•æŠ‰æ‹©ï¼›unwantedï¼šæ— éœ€æ ‡æ³¨çš„ç½‘é¡µï¼›
            "unwanted_reason": "list"
        },
        {
            "track_id": "0b7f2636-d35f-40bf-9b7f-94be4bcbb396",
            "html": "<html><body><h1 cc-select=\"true\">è¿™æ˜¯æ ‡é¢˜</h1></body></html>",   # äººå·¥æ ‡æ³¨å¸¦cc-select="true" å±æ€§
            "groundtruth_content": "# æ ‡é¢˜\n\næ­£æ–‡å†…å®¹",
            "groundtruth_content_list": [
                {"type": "heading", "content": "æ ‡é¢˜", "level": 1},
                {"type": "paragraph", "content": "æ­£æ–‡å†…å®¹"}
            ],
            "url": "https://orderyourbooks.com/product-category/college-books-p-u/?products-per-page=all",
            "layout_id": "orderyourbooks.com_4",
            "max_layer_n": 10,
            "url_host_name": "orderyourbooks.com",
            "raw_warc_path": "s3://cc-raw-huawei/crawl-data/CC-MAIN-2025-13/segments/1742004433093.21/warc/CC-MAIN-20250319080618-20250319110618-00909.warc.gz?bytes=461610805,172252",
            "language": "en",
            "__dom_depth": 19,
            "__dom_width": 10231,
            "__type": "__max_depth",
            "__tag": "DOM_WIDTH",
            "marked_type": "unwanted",  # normalï¼šæ­£å¸¸æ ‡æ³¨çš„ç½‘é¡µï¼›unableï¼šæ­£æ–‡å†…å®¹æ— æ³•æŠ‰æ‹©ï¼›unwantedï¼šæ— éœ€æ ‡æ³¨çš„ç½‘é¡µï¼›
            "unwanted_reason": "list"
        },
    ]
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = BenchmarkDataset(name="sample_dataset", description="ç¤ºä¾‹è¯„æµ‹æ•°æ®é›†")
    
    for sample_data in samples:
        sample = DataSample.from_dict(sample_data)
        dataset.add_sample(sample)
    
    return dataset


def demo_basic_evaluation():
    """æ¼”ç¤ºåŸºæœ¬è¯„æµ‹æµç¨‹"""
    
    print("=== WebMainBench åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹ ===\n")
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(level="INFO")
    
    # 1. åˆ›å»ºæˆ–åŠ è½½æ•°æ®é›†
    print("1. åˆ›å»ºç¤ºä¾‹æ•°æ®é›†...")
    dataset = create_sample_dataset()
    print(f"æ•°æ®é›†åŒ…å« {len(dataset)} ä¸ªæ ·æœ¬")
    print(f"æ•°æ®é›†ç»Ÿè®¡: {dataset.get_statistics()}\n")
    
    # 2. ä¿å­˜æ•°æ®é›†åˆ°æ–‡ä»¶
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)
    
    dataset_path = data_dir / "sample_dataset.jsonl"
    DataSaver.save_jsonl(dataset, dataset_path, include_results=False)
    print(f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {dataset_path}\n")
    
    # 3. é‡æ–°åŠ è½½æ•°æ®é›†
    print("2. é‡æ–°åŠ è½½æ•°æ®é›†...")
    loaded_dataset = DataLoader.load_jsonl(dataset_path)
    print(f"åŠ è½½çš„æ•°æ®é›†åŒ…å« {len(loaded_dataset)} ä¸ªæ ·æœ¬\n")
    
    # 4. åˆ—å‡ºå¯ç”¨çš„æŠ½å–å™¨
    print("3. å¯ç”¨çš„æŠ½å–å™¨:")
    available_extractors = ExtractorFactory.list_available()
    for extractor_name in available_extractors:
        print(f"  - {extractor_name}")
    print()
    
    # 5. åˆ›å»ºè¯„æµ‹å™¨
    print("4. åˆ›å»ºè¯„æµ‹å™¨...")
    evaluator = Evaluator()
    print(f"å¯ç”¨çš„è¯„æµ‹æŒ‡æ ‡: {evaluator.metric_calculator.list_available_metrics()}\n")
    
    # 6. åˆ›å»ºä¸€ä¸ªæ¨¡æ‹ŸæŠ½å–å™¨è¿›è¡Œæ¼”ç¤º
    print("5. åˆ›å»ºæ¨¡æ‹ŸæŠ½å–å™¨...")
    
    from webmainbench.extractors import BaseExtractor, ExtractionResult
    
    class MockExtractor(BaseExtractor):
        """æ¨¡æ‹ŸæŠ½å–å™¨ï¼Œç”¨äºæ¼”ç¤º"""
        
        def _setup(self):
            pass
        
        def _extract_content(self, html, url=None):
            # ç®€å•çš„æ¨¡æ‹ŸæŠ½å–é€»è¾‘
            if "æ ‡é¢˜" in html:
                content = "# æå–çš„æ ‡é¢˜\n\næå–çš„æ­£æ–‡å†…å®¹ã€‚"
                content_list = [
                    {"type": "heading", "content": "æå–çš„æ ‡é¢˜", "level": 1},
                    {"type": "paragraph", "content": "æå–çš„æ­£æ–‡å†…å®¹ã€‚"}
                ]
            else:
                content = "æå–çš„å†…å®¹"
                content_list = [{"type": "paragraph", "content": "æå–çš„å†…å®¹"}]
            
            return ExtractionResult(
                content=content,
                content_list=content_list,
                success=True,
                confidence_score=0.85
            )
    
    # æ³¨å†Œæ¨¡æ‹ŸæŠ½å–å™¨
    ExtractorFactory.register("mock", MockExtractor)
    mock_extractor = ExtractorFactory.create("mock")
    print("æ¨¡æ‹ŸæŠ½å–å™¨å·²åˆ›å»º\n")
    
    # 7. è¿è¡Œè¯„æµ‹
    print("6. è¿è¡Œè¯„æµ‹...")
    result = evaluator.evaluate(
        dataset=loaded_dataset,
        extractor=mock_extractor,
        max_samples=2  # é™åˆ¶æ ·æœ¬æ•°é‡ç”¨äºæ¼”ç¤º
    )
    
    # 8. æ˜¾ç¤ºç»“æœ
    print("\n7. è¯„æµ‹ç»“æœ:")
    print("=" * 50)
    formatted_results = format_results(result.to_dict())
    print(formatted_results)
    
    # 9. ä¿å­˜ç»“æœ
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)
    
    results_path = results_dir / "evaluation_results.json"
    DataSaver.save_evaluation_results(result.to_dict(), results_path)
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    # 10. ç”ŸæˆæŠ¥å‘Š
    report_path = results_dir / "evaluation_report.csv"
    DataSaver.save_summary_report(result.to_dict(), report_path)
    print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


def demo_extractor_comparison():
    """æ¼”ç¤ºå¤šæŠ½å–å™¨å¯¹æ¯”"""
    
    print("\n=== å¤šæŠ½å–å™¨å¯¹æ¯”æ¼”ç¤º ===\n")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = create_sample_dataset()
    
    # åˆ›å»ºå¤šä¸ªæ¨¡æ‹ŸæŠ½å–å™¨
    from webmainbench.extractors import BaseExtractor, ExtractionResult
    
    class ExtractorA(BaseExtractor):
        def _setup(self):
            pass
        def _extract_content(self, html, url=None):
            return ExtractionResult(
                content="æŠ½å–å™¨Açš„ç»“æœ",
                content_list=[{"type": "paragraph", "content": "æŠ½å–å™¨Açš„ç»“æœ"}],
                success=True,
                confidence_score=0.9
            )
    
    class ExtractorB(BaseExtractor):
        def _setup(self):
            pass
        def _extract_content(self, html, url=None):
            return ExtractionResult(
                content="æŠ½å–å™¨Bçš„ç»“æœ",
                content_list=[{"type": "paragraph", "content": "æŠ½å–å™¨Bçš„ç»“æœ"}],
                success=True,
                confidence_score=0.8
            )
    
    # æ³¨å†ŒæŠ½å–å™¨
    ExtractorFactory.register("extractor_a", ExtractorA)
    ExtractorFactory.register("extractor_b", ExtractorB)
    
    # è¿è¡Œå¯¹æ¯”
    evaluator = Evaluator()
    extractors = ["extractor_a", "extractor_b"]
    
    results = evaluator.compare_extractors(
        dataset=dataset,
        extractors=extractors,
        max_samples=2
    )
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print("å¯¹æ¯”ç»“æœ:")
    print("-" * 40)
    for extractor_name, result in results.items():
        overall_score = result.overall_metrics.get('overall', 0)
        print(f"{extractor_name}: {overall_score:.4f}")
    
    # ä¿å­˜å¤šæŠ½å–å™¨å¯¹æ¯”æ¦œå•
    all_results = []
    for extractor_name, result in results.items():
        all_results.append(result.to_dict())
    
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)
    leaderboard_path = results_dir / "leaderboard.csv"
    DataSaver.save_summary_report(all_results, leaderboard_path)
    print(f"\nğŸ“Š æ¦œå•å·²ä¿å­˜åˆ°: {leaderboard_path}")


if __name__ == "__main__":
    try:
        demo_basic_evaluation()
        # demo_extractor_comparison()
        print("\nâœ… ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc() 